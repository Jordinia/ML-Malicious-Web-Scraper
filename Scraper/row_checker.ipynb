{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 268933",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSKRIPSI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m0-49\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProcessed\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdomains_and_content_processed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Step 1: Read the CSV file with proper handling for multiline text in quotes\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_file, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_ALL)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 2: Check the dataframe to ensure it's loaded correctly\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m     (\n\u001b[0;32m   1745\u001b[0m         index,\n\u001b[0;32m   1746\u001b[0m         columns,\n\u001b[0;32m   1747\u001b[0m         col_dict,\n\u001b[1;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m         nrows\n\u001b[0;32m   1750\u001b[0m     )\n\u001b[0;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:843\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:904\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2058\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 268933"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# File path to your CSV\n",
    "input_file = r\"F:\\SKRIPSI\\Dataset\\Data\\0-49\\Processed\\domains_and_content_processed.csv\"\n",
    "\n",
    "# Step 1: Read the CSV file with proper handling for multiline text in quotes\n",
    "df = pd.read_csv(input_file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Step 2: Check the dataframe to ensure it's loaded correctly\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://000studio.com</td>\n",
       "      <td>﻿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://021kongyaji.com</td>\n",
       "      <td>经典好看的电影作品大全_优质高清电影推荐排行榜_第1页_三年片在线观看大全有哪些\\n首页\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://0357yanke.com</td>\n",
       "      <td>仿盛大传奇1.76手机版.1.76版仿盛大热血传奇服务端-新开传奇SF--1.76传奇私服发...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://0724e.com</td>\n",
       "      <td>开云·kaiyun(中国)体育官方网站-登录入口-2017好莱坞大师行，东方好莱坞影视文化基...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://0735lawyer.com</td>\n",
       "      <td>《郴州市律师协会律师微博等自媒体平台使用准则》-行业规范-郴州市律师协会官方网\\n加入收藏\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Domain                                            Content\n",
       "0    http://000studio.com                                                  ﻿\n",
       "1  http://021kongyaji.com  经典好看的电影作品大全_优质高清电影推荐排行榜_第1页_三年片在线观看大全有哪些\\n首页\\n...\n",
       "2    http://0357yanke.com  仿盛大传奇1.76手机版.1.76版仿盛大热血传奇服务端-新开传奇SF--1.76传奇私服发...\n",
       "3        http://0724e.com  开云·kaiyun(中国)体育官方网站-登录入口-2017好莱坞大师行，东方好莱坞影视文化基...\n",
       "4   http://0735lawyer.com  《郴州市律师协会律师微博等自媒体平台使用准则》-行业规范-郴州市律师协会官方网\\n加入收藏\\..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in df is: 1277702\n"
     ]
    }
   ],
   "source": [
    "row_count = len(df)\n",
    "print(f\"The number of rows in df is: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Domain  \\\n",
      "9521    https://judolbet88.live   \n",
      "12472   https://pernusanews.com   \n",
      "19537     https://www.gelora.co   \n",
      "22808  https://www.puskapik.com   \n",
      "\n",
      "                                                 Content  \n",
      "9521   Judolbet88 Situs Info Login Game Gacor Livecha...  \n",
      "12472  Kasum TNI Pimpin Acara Penyerahan Kendaraan Di...  \n",
      "19537  Banyak Video Testimoni Positif di Tengah Kerja...  \n",
      "22808  Tak Temui Deputi II KSP, Begini Klarifikasi Bu...  \n"
     ]
    }
   ],
   "source": [
    "# Search for the word \"gacor\" in the \"Content\" column (case insensitive)\n",
    "gacor_rows = df[df['Content'].str.contains(\"judol\", case=False, na=False)]\n",
    "\n",
    "# Print the rows where \"gacor\" is found\n",
    "print(gacor_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered rows to a new CSV file\n",
    "output_file = \"/home/jordinia/Projects/ML-Malicious-Web-Scraper/casino.csv\"\n",
    "gacor_rows.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://woocommerce.staging-pop.com</td>\n",
       "      <td>visit this web-site Archives - amoxilbest.us.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Domain  \\\n",
       "count                                    84   \n",
       "unique                                   77   \n",
       "top     https://woocommerce.staging-pop.com   \n",
       "freq                                      3   \n",
       "\n",
       "                                                  Content  \n",
       "count                                                  84  \n",
       "unique                                                 84  \n",
       "top     visit this web-site Archives - amoxilbest.us.c...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# File path to your CSV\n",
    "input_file = \"/home/jordinia/Projects/ML-Malicious-Web-Scraper/gamblinggacor.csv\"\n",
    "\n",
    "# Step 1: Read the CSV file with proper handling for multiline text in quotes\n",
    "df = pd.read_csv(input_file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Step 2: Check the dataframe to ensure it's loaded correctly\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain                                      http://aa.oma.be\n",
      "Content    MESS / Mass loss from Evolved Stars | Astronom...\n",
      "Name: 59, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[59])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[16161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the input CSV file with domains\n",
    "input_csv = '/mnt/f/SKRIPSI/Data/Processed/domains_and_content_processed.csv'\n",
    "\n",
    "# Path to the output CSV file for processed domains\n",
    "output_csv = '/mnt/f/SKRIPSI/Data/Processed/domains_processed.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(input_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of rows in df is: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates in the DataFrame based on the 'Domain' column\n",
    "duplicates = df[df.duplicated(subset=['Domain'])]\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicates = len(duplicates)\n",
    "\n",
    "# Print the number of duplicates\n",
    "print(f\"The number of duplicate rows in df is: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on the 'Domain' column\n",
    "df_processed = df.drop_duplicates(subset=['Domain'])\n",
    "\n",
    "# Count the number of rows in the processed DataFrame\n",
    "row_count = len(df_processed)\n",
    "\n",
    "# Print the row count\n",
    "print(f\"The CSV file contains {row_count} unique domains.\")\n",
    "\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "df_processed.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Processed domains saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
