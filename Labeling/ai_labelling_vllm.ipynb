{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95531198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()  \n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    chat_url: str\n",
    "    model_name: str\n",
    "    input_suffix: str\n",
    "    max_content_length: int = 1750\n",
    "    retry_attempts: int = 3\n",
    "    retry_delay: int = 5\n",
    "    max_tokens: int = 14000\n",
    "    temperature: float = 0.6\n",
    "    seed: int = 111\n",
    "\n",
    "@dataclass\n",
    "class ProcessingConfig:\n",
    "    input_file: str\n",
    "    output_label_file: str\n",
    "    output_fixed_file: str\n",
    "    label_prompt_file: str\n",
    "    start_row: int = 0\n",
    "    batch_size: int = 100\n",
    "\n",
    "class DomainClassifier:\n",
    "    def __init__(self, model_config: ModelConfig):\n",
    "        self.config = model_config\n",
    "        self.setup_logging()\n",
    "        self.setup_csv_limits()\n",
    "        \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging system\"\"\"\n",
    "        log_dir = Path('logs')\n",
    "        log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        log_filename = log_dir / f'domain_classification_{timestamp}.log'\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_filename),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging\n",
    "        self.logger.info(f\"Logging to: {log_filename}\")\n",
    "\n",
    "    def setup_csv_limits(self):\n",
    "        \"\"\"Handle CSV field size limits\"\"\"\n",
    "        maxInt = sys.maxsize\n",
    "        while True:\n",
    "            try:\n",
    "                csv.field_size_limit(maxInt)\n",
    "                break\n",
    "            except OverflowError:\n",
    "                maxInt = int(maxInt/10)\n",
    "\n",
    "    def check_model_health(self) -> bool:\n",
    "        \"\"\"Check if the vLLM server is healthy and the model is loaded\"\"\"\n",
    "        try:\n",
    "            # Test with a simple request\n",
    "            test_payload = {\n",
    "                \"model\": self.config.model_name,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "                \"max_tokens\": 10,\n",
    "                \"temperature\": 0.1\n",
    "            }\n",
    "            \n",
    "            response = requests.post(\n",
    "                self.config.chat_url,\n",
    "                json=test_payload,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                self.logger.info(f\"Model {self.config.model_name} is ready\")\n",
    "                return True\n",
    "            else:\n",
    "                self.logger.error(f\"Model health check failed: {response.status_code}, {response.text}\")\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error checking model health: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def sample_content(self, content: str) -> str:\n",
    "        \"\"\"Sample content to fit within length limits while preserving context\"\"\"\n",
    "        if len(content) <= self.config.max_content_length:\n",
    "            return content\n",
    "        \n",
    "        # Calculate balanced chunks\n",
    "        start_len = int(self.config.max_content_length * 0.2)  # 20% for start\n",
    "        end_len = int(self.config.max_content_length * 0.2)    # 20% for end\n",
    "        mid_len = self.config.max_content_length - (start_len + end_len)\n",
    "        \n",
    "        start = content[:start_len]\n",
    "        mid_point = len(content) // 2\n",
    "        mid = content[mid_point - mid_len//2:mid_point + mid_len//2]\n",
    "        end = content[-end_len:]\n",
    "        \n",
    "        return f\"{start}... {mid}... {end}\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_classification_consistency(answer: int, classification: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the numerical answer matches the text classification\n",
    "        Updated for 4 categories\n",
    "        \"\"\"\n",
    "        classification = str(classification).lower()\n",
    "        \n",
    "        if answer == 0 and \"benign\" in classification:\n",
    "            return True\n",
    "        elif answer == 1 and \"gambling\" in classification:\n",
    "            return True\n",
    "        elif answer == 2 and any(word in classification for word in [\"porn\", \"adult\"]):\n",
    "            return True\n",
    "        elif answer == 3 and any(word in classification for word in [\"harmful\", \"illegal\"]):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def send_classification_request(self, conversation: List[Dict]) -> Tuple[dict, float]:\n",
    "        \"\"\"Send classification request to vLLM with retry logic and parse thought/JSON\"\"\"\n",
    "        for attempt in range(self.config.retry_attempts):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                payload = {\n",
    "                    \"model\": self.config.model_name,\n",
    "                    \"messages\": conversation,\n",
    "                    \"max_tokens\": self.config.max_tokens,\n",
    "                    \"temperature\": self.config.temperature,\n",
    "                    \"seed\": self.config.seed,\n",
    "                    \"stream\": False\n",
    "                }\n",
    "                \n",
    "                response = requests.post(\n",
    "                    self.config.chat_url,\n",
    "                    json=payload,\n",
    "                    timeout=120,  # Increased timeout for vLLM\n",
    "                    headers={\"Content-Type\": \"application/json\"}\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    elapsed_time = time.time() - start_time\n",
    "                    response_json = response.json()\n",
    "                    \n",
    "                    # Extract content from vLLM response format\n",
    "                    choices = response_json.get(\"choices\", [])\n",
    "                    if not choices:\n",
    "                        self.logger.error(\"No choices in response\")\n",
    "                        continue\n",
    "                        \n",
    "                    message_content = choices[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "                    \n",
    "                    if not message_content:\n",
    "                        self.logger.error(\"Empty message content\")\n",
    "                        continue\n",
    "\n",
    "                    # Extract the <think> reasoning part\n",
    "                    thought_match = re.search(r\"<think>\\n(.*?)\\n</think>\", message_content, re.DOTALL)\n",
    "                    thought = thought_match.group(1).strip() if thought_match else \"No thought found.\"\n",
    "\n",
    "                    # Extract the JSON output\n",
    "                    json_match = re.search(r\"```json\\n(.*?)\\n```\", message_content, re.DOTALL)\n",
    "                    if json_match:\n",
    "                        try:\n",
    "                            result = json.loads(json_match.group(1))\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            self.logger.error(f\"JSON decode error: {e}\")\n",
    "                            result = {}\n",
    "                    else:\n",
    "                        # Try to find JSON without code blocks\n",
    "                        json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', message_content)\n",
    "                        if json_match:\n",
    "                            try:\n",
    "                                result = json.loads(json_match.group(0))\n",
    "                            except json.JSONDecodeError:\n",
    "                                result = {}\n",
    "                        else:\n",
    "                            result = {}\n",
    "                    \n",
    "                    # Add thought to result\n",
    "                    result[\"thought\"] = thought\n",
    "                    \n",
    "                    # Log usage statistics if available\n",
    "                    usage = response_json.get(\"usage\", {})\n",
    "                    if usage:\n",
    "                        self.logger.debug(f\"Token usage - Prompt: {usage.get('prompt_tokens', 0)}, \"\n",
    "                                        f\"Completion: {usage.get('completion_tokens', 0)}, \"\n",
    "                                        f\"Total: {usage.get('total_tokens', 0)}\")\n",
    "\n",
    "                    return result, elapsed_time\n",
    "                else:\n",
    "                    self.logger.error(f\"HTTP error {response.status_code}: {response.text}\")\n",
    "                        \n",
    "                if attempt < self.config.retry_attempts - 1:\n",
    "                    time.sleep(self.config.retry_delay)\n",
    "                    \n",
    "            except requests.exceptions.Timeout:\n",
    "                self.logger.error(f\"Request timeout (attempt {attempt+1})\")\n",
    "                if attempt < self.config.retry_attempts - 1:\n",
    "                    time.sleep(self.config.retry_delay)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Request error (attempt {attempt+1}): {str(e)}\")\n",
    "                if attempt < self.config.retry_attempts - 1:\n",
    "                    time.sleep(self.config.retry_delay)\n",
    "        \n",
    "        return {}, 0.0\n",
    "\n",
    "    def process_dataset(self, processing_config: ProcessingConfig):\n",
    "        \"\"\"Process the dataset with enhanced error handling and logging\"\"\"\n",
    "        EXPECTED_CLASSIFICATION = {\n",
    "            0: \"Benign\",\n",
    "            1: \"Gambling\",\n",
    "            2: \"Pornography\",\n",
    "            3: \"Harmful\"\n",
    "        }\n",
    "        try:\n",
    "            if not self.check_model_health():\n",
    "                raise Exception(\"Model health check failed\")\n",
    "            \n",
    "            Path(processing_config.output_label_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "            Path(processing_config.output_fixed_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Count total rows for progress bar\n",
    "            total_rows = 0\n",
    "            with open(processing_config.input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "                reader = csv.DictReader(infile)\n",
    "                total_rows = sum(1 for _ in reader) - processing_config.start_row\n",
    "            \n",
    "            countrow = processing_config.start_row\n",
    "\n",
    "            with open(processing_config.output_label_file, 'w', newline='', encoding='utf-8') as label_file, \\\n",
    "                 open(processing_config.output_fixed_file, 'w', newline='', encoding='utf-8') as fixed_file, \\\n",
    "                 open(processing_config.label_prompt_file, \"r\") as prompt_file:\n",
    "                \n",
    "                label_writer = csv.DictWriter(label_file, \n",
    "                    fieldnames=['Domain', 'Content', 'Label', 'Classification', 'Reason', 'Confidence', 'Thought'])\n",
    "                fixed_writer = csv.DictWriter(fixed_file, \n",
    "                    fieldnames=['Domain', 'Content', 'Label', 'Confidence'])\n",
    "                \n",
    "                labelling_prompt = prompt_file.read()\n",
    "                \n",
    "                label_writer.writeheader()\n",
    "                fixed_writer.writeheader()\n",
    "\n",
    "                del label_file, fixed_file, prompt_file\n",
    "\n",
    "                with open(processing_config.input_file, 'r', newline='', encoding='utf-8') as infile:\n",
    "                    reader = csv.DictReader(infile)\n",
    "                    \n",
    "                    # Skip to start row\n",
    "                    for _ in range(processing_config.start_row):\n",
    "                        next(reader, None)\n",
    "                    \n",
    "                    # Create progress bar\n",
    "                    progress_bar = tqdm(\n",
    "                        total=total_rows,\n",
    "                        desc=\"Classifying domains\",\n",
    "                        unit=\"samples\",\n",
    "                        unit_scale=True,\n",
    "                        dynamic_ncols=True,\n",
    "                        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
    "                    )\n",
    "                    \n",
    "                    try:\n",
    "                        for row in reader:\n",
    "                            domain = row['Domain']\n",
    "                            content = row['Content']\n",
    "                            \n",
    "                            sampled_content = self.sample_content(content)\n",
    "                            input_text = f\"{self.config.input_suffix}\\n{domain},\\\"{sampled_content}\\\"\"\n",
    "                            \n",
    "                            conversation = [\n",
    "                                {\"role\": \"system\", \"content\": labelling_prompt},\n",
    "                                {\"role\": \"user\", \"content\": input_text}\n",
    "                            ]\n",
    "                            \n",
    "                            result, elapsed_time = self.send_classification_request(conversation)\n",
    "\n",
    "                            # Extract fields with fallbacks\n",
    "                            answer = int(result.get('answer', -1))\n",
    "                            classification = str(result.get('classification', 'Unknown'))\n",
    "                            reason = str(result.get('reason', 'No reason provided'))\n",
    "                            confidence = int(result.get('confidence', 0))\n",
    "                            thought = str(result.get('thought', 'No reasoning captured'))\n",
    "\n",
    "                            label_writer.writerow({\n",
    "                                'Domain': domain,\n",
    "                                'Content': content,\n",
    "                                'Label': answer,\n",
    "                                'Classification': classification,\n",
    "                                'Reason': reason,\n",
    "                                'Confidence': confidence,\n",
    "                                'Thought': thought\n",
    "                            })\n",
    "                            \n",
    "                            fixed_writer.writerow({\n",
    "                                'Domain': domain,\n",
    "                                'Content': content,\n",
    "                                'Label': answer,\n",
    "                                'Confidence': confidence\n",
    "                            })\n",
    "                            \n",
    "                            # Update progress bar with additional info\n",
    "                            progress_bar.set_postfix({\n",
    "                                'Current': domain[:20] + '...' if len(domain) > 20 else domain,\n",
    "                                'Label': answer,\n",
    "                                'Time': f\"{elapsed_time:.2f}s\"\n",
    "                            })\n",
    "                            progress_bar.update(1)\n",
    "                            \n",
    "                            # Log less frequently to avoid cluttering with progress bar\n",
    "                            if countrow % 500 == 0:  # Log every 10th item\n",
    "                                self.logger.info(f\"Processed {countrow}: {domain} -> {answer} ({elapsed_time:.2f}s)\")\n",
    "\n",
    "                            if not DomainClassifier.check_classification_consistency(answer, classification):\n",
    "                                self.logger.warning(\n",
    "                                    f\"Hallucination detected for {countrow} {row['Domain']}, \"\n",
    "                                    f\"Answer: {answer} ({EXPECTED_CLASSIFICATION.get(answer)}), \"\n",
    "                                    f\"Classification: {classification}, \"\n",
    "                                    f\"Reason: {reason} \"\n",
    "                                    f\"Confidence: {confidence} \\n\"\n",
    "                                    f\"Raw Output: {result} \"\n",
    "                                )\n",
    "                            countrow += 1\n",
    "                    \n",
    "                    finally:\n",
    "                        progress_bar.close()\n",
    "                        \n",
    "                    self.logger.info(f\"Processing completed. Total processed: {countrow - processing_config.start_row}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Processing error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_config = ModelConfig(\n",
    "        chat_url=os.getenv(\"VLLM_CHAT_URL\", \"http://localhost:8000/v1/chat/completions\"),\n",
    "        model_name=os.getenv(\"MODEL_NAME\", \"jordinia/NetPro-Qwen3-0.6B-2105\"),\n",
    "        input_suffix=\"Classify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n\",\n",
    "        max_content_length=20000,\n",
    "        max_tokens=14000,\n",
    "        temperature=0.6,\n",
    "        seed=111\n",
    "    )\n",
    "    \n",
    "    processing_config = ProcessingConfig(\n",
    "        input_file=\"/home/fishmon/AJ/LLM-Finetuning/Malicious-Web/dataset/test.csv\",\n",
    "        output_label_file=\"NetPro-Qwen3-0.6B-2105_label_full.csv\",\n",
    "        output_fixed_file=\"NetPro-Qwen3-0.6B-2105_fixed_full.csv\",\n",
    "        label_prompt_file=\"prompts/labelling/labelling_promptv4.txt\",\n",
    "        start_row=0\n",
    "    )\n",
    "    \n",
    "    classifier = DomainClassifier(model_config)\n",
    "    classifier.process_dataset(processing_config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
